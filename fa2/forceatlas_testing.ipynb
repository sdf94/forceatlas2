{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.mass = 0.0\n",
    "        self.old_dx = 0.0\n",
    "        self.old_dy = 0.0\n",
    "        self.dx = 0.0\n",
    "        self.dy = 0.0\n",
    "        self.x = 0.0\n",
    "        self.y = 0.0\n",
    "        self.size = 0.\n",
    "\n",
    "\n",
    "# This is not in the original java code, but it makes it easier to deal with edges\n",
    "class Edge:\n",
    "    def __init__(self):\n",
    "        self.node1 = -1\n",
    "        self.node2 = -1\n",
    "        self.weight = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linRepulsion(n1, n2, coefficient=0):\n",
    "    xDist = n1.x - n2.x\n",
    "    yDist = n1.y - n2.y\n",
    "    \n",
    "    distance = sqrt(xDist **2 + yDist**2) - (n1.size + n2.size)\n",
    "    \n",
    "    if distance > 0: # Clearly distance is always positive without collision detection\n",
    "        factor = coefficient * n1.mass * n2.mass / distance**2\n",
    "    elif distance < 0: # If the distance is smaller than the sum of radiuses then increase the repulsion\n",
    "        factor = 100 * coefficient * n1.mass * n2.mass\n",
    "        \n",
    "    else: # If distance is 0 do nothing\n",
    "        return\n",
    "    # Apply the force\n",
    "    n1.dx += xDist * factor\n",
    "    n1.dy += yDist * factor\n",
    "    n2.dx -= xDist * factor\n",
    "    n2.dy -= yDist * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linRepulsion_region(n, r, coefficient=0):\n",
    "    xDist = n.x - r.massCenterX\n",
    "    yDist = n.y - r.massCenterY\n",
    "    distance2 = sqrt(xDist **2 + yDist**2)\n",
    "\n",
    "    if distance2 > 0:\n",
    "        factor = coefficient * n.mass * r.mass / distance2\n",
    "        n.dx += xDist * factor\n",
    "        n.dy += yDist * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linAttraction(n1, n2, e, distributedAttraction, coefficient=0):\n",
    "    xDist = n1.x - n2.x\n",
    "    yDist = n1.y - n2.y\n",
    "    distance = sqrt(xDist**2 + yDist**2) - n1.size - n2.size\n",
    "    \n",
    "    if distance > 0:\n",
    "        if not distributedAttraction:\n",
    "            factor = -coefficient * e * distance\n",
    "        else:\n",
    "            factor = -coefficient * e * distance / n1.mass\n",
    "        n1.dx += xDist * factor\n",
    "        n1.dy += yDist * factor\n",
    "        n2.dx -= xDist * factor\n",
    "        n2.dy -= yDist * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linGravity(n, g):\n",
    "    xDist = n.x\n",
    "    yDist = n.y\n",
    "    distance = sqrt(xDist **2 + yDist **2)\n",
    "\n",
    "    if distance > 0:\n",
    "        factor = n.mass * g / distance\n",
    "        n.dx -= xDist * factor\n",
    "        n.dy -= yDist * factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_repulsion(nodes, coefficient):\n",
    "    i = 0\n",
    "    for n1 in nodes:\n",
    "        j = i\n",
    "        for n2 in nodes:\n",
    "            if j == 0:\n",
    "                break\n",
    "            linRepulsion(n1, n2, coefficient)\n",
    "            j -= 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gravity(nodes, gravity):\n",
    "    for n in nodes:\n",
    "        linGravity(n, gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attraction(nodes, edges, distributedAttraction, coefficient, edgeWeightInfluence):\n",
    "    # Optimization, since usually edgeWeightInfluence is 0 or 1, and pow is slow\n",
    "    if edgeWeightInfluence == 0:\n",
    "        for edge in edges:\n",
    "            linAttraction(nodes[edge.node1], nodes[edge.node2], 1, distributedAttraction, coefficient)\n",
    "    elif edgeWeightInfluence == 1:\n",
    "        for edge in edges:\n",
    "            linAttraction(nodes[edge.node1], nodes[edge.node2], edge.weight, distributedAttraction, coefficient)\n",
    "    else:\n",
    "        for edge in edges:\n",
    "            linAttraction(nodes[edge.node1], nodes[edge.node2], pow(edge.weight, edgeWeightInfluence),\n",
    "                          distributedAttraction, coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cython detected.  Install cython and compile the fa2util module for a 10-100x speed boost.\n"
     ]
    }
   ],
   "source": [
    "class Region:\n",
    "    def __init__(self, nodes):\n",
    "        self.mass = 0.0\n",
    "        self.massCenterX = 0.0\n",
    "        self.massCenterY = 0.0\n",
    "        self.size = 0.0\n",
    "        self.nodes = nodes\n",
    "        self.subregions = []\n",
    "        self.updateMassAndGeometry()\n",
    "\n",
    "    def updateMassAndGeometry(self):\n",
    "        if len(self.nodes) > 1:\n",
    "            self.mass = 0\n",
    "            massSumX = 0\n",
    "            massSumY = 0\n",
    "            for n in self.nodes:\n",
    "                self.mass += n.mass\n",
    "                massSumX += n.x * n.mass\n",
    "                massSumY += n.y * n.mass\n",
    "            self.massCenterX = massSumX / self.mass\n",
    "            self.massCenterY = massSumY / self.mass\n",
    "\n",
    "            self.size = 0.0\n",
    "            for n in self.nodes:\n",
    "                distance = sqrt((n.x - self.massCenterX) ** 2 + (n.y - self.massCenterY) ** 2)\n",
    "                self.size = max(self.size, 2 * distance)\n",
    "\n",
    "    def buildSubRegions(self):\n",
    "        if len(self.nodes) > 1:\n",
    "\n",
    "            leftNodes = []\n",
    "            rightNodes = []\n",
    "            for n in self.nodes:\n",
    "                if n.x < self.massCenterX:\n",
    "                    leftNodes.append(n)\n",
    "                else:\n",
    "                    rightNodes.append(n)\n",
    "\n",
    "            topleftNodes = []\n",
    "            bottomleftNodes = []\n",
    "            for n in leftNodes:\n",
    "                if n.y < self.massCenterY:\n",
    "                    topleftNodes.append(n)\n",
    "                else:\n",
    "                    bottomleftNodes.append(n)\n",
    "\n",
    "            toprightNodes = []\n",
    "            bottomrightNodes = []\n",
    "            for n in rightNodes:\n",
    "                if n.y < self.massCenterY:\n",
    "                    toprightNodes.append(n)\n",
    "                else:\n",
    "                    bottomrightNodes.append(n)\n",
    "\n",
    "            if len(topleftNodes) > 0:\n",
    "                if len(topleftNodes) < len(self.nodes):\n",
    "                    subregion = Region(topleftNodes)\n",
    "                    self.subregions.append(subregion)\n",
    "                else:\n",
    "                    for n in topleftNodes:\n",
    "                        subregion = Region([n])\n",
    "                        self.subregions.append(subregion)\n",
    "\n",
    "            if len(bottomleftNodes) > 0:\n",
    "                if len(bottomleftNodes) < len(self.nodes):\n",
    "                    subregion = Region(bottomleftNodes)\n",
    "                    self.subregions.append(subregion)\n",
    "                else:\n",
    "                    for n in bottomleftNodes:\n",
    "                        subregion = Region([n])\n",
    "                        self.subregions.append(subregion)\n",
    "\n",
    "            if len(toprightNodes) > 0:\n",
    "                if len(toprightNodes) < len(self.nodes):\n",
    "                    subregion = Region(toprightNodes)\n",
    "                    self.subregions.append(subregion)\n",
    "                else:\n",
    "                    for n in toprightNodes:\n",
    "                        subregion = Region([n])\n",
    "                        self.subregions.append(subregion)\n",
    "\n",
    "            if len(bottomrightNodes) > 0:\n",
    "                if len(bottomrightNodes) < len(self.nodes):\n",
    "                    subregion = Region(bottomrightNodes)\n",
    "                    self.subregions.append(subregion)\n",
    "                else:\n",
    "                    for n in bottomrightNodes:\n",
    "                        subregion = Region([n])\n",
    "                        self.subregions.append(subregion)\n",
    "\n",
    "            for subregion in self.subregions:\n",
    "                subregion.buildSubRegions()\n",
    "\n",
    "    def applyForce(self, n, theta, coefficient=0):\n",
    "        if len(self.nodes) < 2:\n",
    "            linRepulsion(n, self.nodes[0], coefficient)\n",
    "        else:\n",
    "            distance = sqrt((n.x - self.massCenterX) ** 2 + (n.y - self.massCenterY) ** 2)\n",
    "            if distance * theta > self.size:\n",
    "                linRepulsion_region(n, self, coefficient)\n",
    "            else:\n",
    "                for subregion in self.subregions:\n",
    "                    subregion.applyForce(n, theta, coefficient)\n",
    "\n",
    "    def applyForceOnNodes(self, nodes, theta, coefficient=0): \n",
    "        for n in nodes:\n",
    "            self.applyForce(n, theta, coefficient)\n",
    "\n",
    "\n",
    "# Adjust speed and apply forces step\n",
    "def adjustSpeedAndApplyForces(nodes, speed, speedEfficiency, jitterTolerance):\n",
    "    # Auto adjust speed.\n",
    "    totalSwinging = 0.0  # How much irregular movement\n",
    "    totalEffectiveTraction = 0.0  # How much useful movement\n",
    "    for n in nodes:\n",
    "        swinging = sqrt((n.old_dx - n.dx) * (n.old_dx - n.dx) + (n.old_dy - n.dy) * (n.old_dy - n.dy))\n",
    "        totalSwinging += n.mass * swinging\n",
    "        totalEffectiveTraction += .5 * n.mass * sqrt(\n",
    "            (n.old_dx + n.dx) * (n.old_dx + n.dx) + (n.old_dy + n.dy) * (n.old_dy + n.dy))\n",
    "\n",
    "    # Optimize jitter tolerance.  The 'right' jitter tolerance for\n",
    "    # this network. Bigger networks need more tolerance. Denser\n",
    "    # networks need less tolerance. Totally empiric.\n",
    "    estimatedOptimalJitterTolerance = .05 * sqrt(len(nodes))\n",
    "    minJT = sqrt(estimatedOptimalJitterTolerance)\n",
    "    maxJT = 10\n",
    "    jt = jitterTolerance * max(minJT,\n",
    "                               min(maxJT, estimatedOptimalJitterTolerance * totalEffectiveTraction / (\n",
    "                                   len(nodes) * len(nodes))))\n",
    "\n",
    "    minSpeedEfficiency = 0.05\n",
    "\n",
    "    # Protective against erratic behavior\n",
    "    if totalSwinging / totalEffectiveTraction > 2.0:\n",
    "        if speedEfficiency > minSpeedEfficiency:\n",
    "            speedEfficiency *= .5\n",
    "        jt = max(jt, jitterTolerance)\n",
    "\n",
    "    if totalSwinging == 0:\n",
    "        targetSpeed = float('inf')\n",
    "    else:\n",
    "        targetSpeed = jt * speedEfficiency * totalEffectiveTraction / totalSwinging\n",
    "\n",
    "    if totalSwinging > jt * totalEffectiveTraction:\n",
    "        if speedEfficiency > minSpeedEfficiency:\n",
    "            speedEfficiency *= .7\n",
    "    elif speed < 1000:\n",
    "        speedEfficiency *= 1.3\n",
    "\n",
    "    # But the speed shoudn't rise too much too quickly, since it would\n",
    "    # make the convergence drop dramatically.\n",
    "    maxRise = .5\n",
    "    speed = speed + min(targetSpeed - speed, maxRise * speed)\n",
    "\n",
    "    # Apply forces.\n",
    "    #\n",
    "    # Need to add a case if adjustSizes (\"prevent overlap\") is\n",
    "    # implemented.\n",
    "    for n in nodes:\n",
    "        swinging = n.mass * sqrt((n.old_dx - n.dx) * (n.old_dx - n.dx) + (n.old_dy - n.dy) * (n.old_dy - n.dy))\n",
    "        factor = 0.1 * speed / (1.0 + sqrt(speed * swinging))\n",
    "        df = sqrt(n.dx**2 + n.dy**2)\n",
    "        factor = min(factor * df, 10.) / df\n",
    "        n.x = n.x + (n.dx * factor)\n",
    "        n.y = n.y + (n.dy * factor)\n",
    "\n",
    "    values = {}\n",
    "    values['speed'] = speed\n",
    "    values['speedEfficiency'] = speedEfficiency\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "try:\n",
    "    import cython\n",
    "\n",
    "    if not cython.compiled:\n",
    "        print(\"Warning: uncompiled fa2util module.  Compile with cython for a 10-100x speed boost.\")\n",
    "except:\n",
    "    print(\"No cython detected.  Install cython and compile the fa2util module for a 10-100x speed boost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, name=\"Timer\"):\n",
    "        self.name = name\n",
    "        self.start_time = 0.0\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        self.total_time += (time.time() - self.start_time)\n",
    "\n",
    "    def display(self):\n",
    "        print(self.name, \" took \", \"%.2f\" % self.total_time, \" seconds\")\n",
    "\n",
    "\n",
    "class ForceAtlas2:\n",
    "    def __init__(self,\n",
    "                 # Behavior alternatives\n",
    "                 outboundAttractionDistribution=False,  # Dissuade hubs\n",
    "                 linLogMode=False, # Prevent overlap (NOT IMPLEMENTED)\n",
    "                 edgeWeightInfluence=1.0,\n",
    "\n",
    "                 # Performance\n",
    "                 jitterTolerance=1.0,  # Tolerance\n",
    "                 barnesHutOptimize=True,\n",
    "                 barnesHutTheta=1.2,\n",
    "                 multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                 # Tuning\n",
    "                 scalingRatio=2.0,\n",
    "                 gravity=1.0,\n",
    "\n",
    "                 # Log\n",
    "                 verbose=True):\n",
    "        assert linLogMode == multiThreaded == False, \"You selected a feature that has not been implemented yet...\"\n",
    "        self.outboundAttractionDistribution = outboundAttractionDistribution\n",
    "        self.linLogMode = linLogMode\n",
    "        self.edgeWeightInfluence = edgeWeightInfluence\n",
    "        self.jitterTolerance = jitterTolerance\n",
    "        self.barnesHutOptimize = barnesHutOptimize\n",
    "        self.barnesHutTheta = barnesHutTheta\n",
    "        self.scalingRatio = scalingRatio\n",
    "        self.gravity = gravity\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def init(self,\n",
    "             G,  # a graph in 2D numpy ndarray format (or) scipy sparse matrix format\n",
    "             pos=None,  # Array of initial positions\n",
    "             sizes=None # Array of node sizes \n",
    "             ):\n",
    "        isSparse = False\n",
    "        if isinstance(G, numpy.ndarray):\n",
    "            # Check our assumptions\n",
    "            assert G.shape == (G.shape[0], G.shape[0]), \"G is not 2D square\"\n",
    "            assert numpy.all(G.T == G), \"G is not symmetric.  Currently only undirected graphs are supported\"\n",
    "            assert isinstance(pos, numpy.ndarray) or (pos is None), \"Invalid node positions\"\n",
    "        elif scipy.sparse.issparse(G):\n",
    "            # Check our assumptions\n",
    "            assert G.shape == (G.shape[0], G.shape[0]), \"G is not 2D square\"\n",
    "            assert isinstance(pos, numpy.ndarray) or (pos is None), \"Invalid node positions\"\n",
    "            G = G.tolil()\n",
    "            isSparse = True\n",
    "        else:\n",
    "            assert False, \"G is not numpy ndarray or scipy sparse matrix\"\n",
    "            \n",
    "        assert isinstance(sizes, numpy.ndarray) or (sizes is None), \"Invalid node sizes\"\n",
    "\n",
    "        # Put nodes into a data structure we can understand\n",
    "        nodes = []\n",
    "        history = []\n",
    "        for i in range(0, G.shape[0]):\n",
    "            n = Node()\n",
    "            if isSparse:\n",
    "                n.mass = 1 + len(G.rows[i])\n",
    "            else:\n",
    "                n.mass = 1 + numpy.count_nonzero(G[i])\n",
    "            n.old_dx = 0\n",
    "            n.old_dy = 0\n",
    "            n.dx = 0\n",
    "            n.dy = 0\n",
    "            if pos is None:\n",
    "                n.x = random.random()\n",
    "                n.y = random.random()\n",
    "            else:\n",
    "                n.x = pos[i][0]\n",
    "                n.y = pos[i][1]\n",
    "\n",
    "            if sizes is not None:\n",
    "                n.size = sizes[i]\n",
    "            nodes.append(n)\n",
    "\n",
    "        # Put edges into a data structure we can understand\n",
    "        edges = []\n",
    "        es = numpy.asarray(G.nonzero()).T\n",
    "        for e in es:  # Iterate through edges\n",
    "            if e[1] <= e[0]: continue  # Avoid duplicate edges\n",
    "            edge = Edge()\n",
    "            edge.node1 = e[0]  # The index of the first node in `nodes`\n",
    "            edge.node2 = e[1]  # The index of the second node in `nodes`\n",
    "            edge.weight = G[tuple(e)]\n",
    "            edges.append(edge)\n",
    "\n",
    "        return nodes, edges\n",
    "\n",
    "    # Given an adjacency matrix, this function computes the node positions\n",
    "    # according to the ForceAtlas2 layout algorithm.  It takes the same\n",
    "    # arguments that one would give to the ForceAtlas2 algorithm in Gephi.\n",
    "    # Not all of them are implemented.  See below for a description of\n",
    "    # each parameter and whether or not it has been implemented.\n",
    "    #\n",
    "    # This function will return a list of X-Y coordinate tuples, ordered\n",
    "    # in the same way as the rows/columns in the input matrix.\n",
    "    #\n",
    "    # The only reason you would want to run this directly is if you don't\n",
    "    # use networkx.  In this case, you'll likely need to convert the\n",
    "    # output to a more usable format.  If you do use networkx, use the\n",
    "    # \"forceatlas2_networkx_layout\" function below.\n",
    "    #\n",
    "    # Currently, only undirected graphs are supported so the adjacency matrix\n",
    "    # should be symmetric.\n",
    "    def forceatlas2(self,\n",
    "                    G,  # a graph in 2D numpy ndarray format (or) scipy sparse matrix format\n",
    "                    pos=None,  # Array of initial positions,\n",
    "                    sizes=None,\n",
    "                    iterations=100,  # Number of times to iterate the main loop\n",
    "                    keep_history=False # Whether or not to return the historical values while fa2 is running\n",
    "                    ):\n",
    "        # Initializing, initAlgo()\n",
    "        # ================================================================\n",
    "\n",
    "        # speed and speedEfficiency describe a scaling factor of dx and dy\n",
    "        # before x and y are adjusted.  These are modified as the\n",
    "        # algorithm runs to help ensure convergence.\n",
    "        speed = 1.0\n",
    "        speedEfficiency = 1.0\n",
    "        nodes, edges = self.init(G, pos,sizes)\n",
    "        outboundAttCompensation = 1.0\n",
    "        if self.outboundAttractionDistribution:\n",
    "            outboundAttCompensation = numpy.mean([n.mass for n in nodes])\n",
    "        # ================================================================\n",
    "\n",
    "        # Main loop, i.e. goAlgo()\n",
    "        # ================================================================\n",
    "\n",
    "        barneshut_timer = Timer(name=\"BarnesHut Approximation\")\n",
    "        repulsion_timer = Timer(name=\"Repulsion forces\")\n",
    "        gravity_timer = Timer(name=\"Gravitational forces\")\n",
    "        attraction_timer = Timer(name=\"Attraction forces\")\n",
    "        applyforces_timer = Timer(name=\"AdjustSpeedAndApplyForces step\")\n",
    "\n",
    "        # Each iteration of this loop represents a call to goAlgo().\n",
    "        niters = range(iterations)\n",
    "        if self.verbose:\n",
    "            niters = tqdm(niters)\n",
    "        history = []\n",
    "        for _i in niters:\n",
    "            for n in nodes:\n",
    "                n.old_dx = n.dx\n",
    "                n.old_dy = n.dy\n",
    "                n.dx = 0\n",
    "                n.dy = 0\n",
    "\n",
    "            # Barnes Hut optimization\n",
    "            if self.barnesHutOptimize:\n",
    "                barneshut_timer.start()\n",
    "                rootRegion = Region(nodes)\n",
    "                rootRegion.buildSubRegions()\n",
    "                barneshut_timer.stop()\n",
    "\n",
    "            # Charge repulsion forces\n",
    "            repulsion_timer.start()\n",
    "            # parallelization should be implemented here\n",
    "            if self.barnesHutOptimize:\n",
    "                rootRegion.applyForceOnNodes(nodes, self.barnesHutTheta, self.scalingRatio)\n",
    "            else:\n",
    "                apply_repulsion(nodes, self.scalingRatio)\n",
    "            repulsion_timer.stop()\n",
    "\n",
    "            # Gravitational forces\n",
    "            gravity_timer.start()\n",
    "            apply_gravity(nodes, self.gravity)\n",
    "            gravity_timer.stop()\n",
    "\n",
    "            # If other forms of attraction were implemented they would be selected here.\n",
    "            attraction_timer.start()\n",
    "            apply_attraction(nodes, edges, self.outboundAttractionDistribution, outboundAttCompensation,\n",
    "                                     self.edgeWeightInfluence)\n",
    "            attraction_timer.stop()\n",
    "\n",
    "            # Adjust speeds and apply forces\n",
    "            applyforces_timer.start()\n",
    "            values = adjustSpeedAndApplyForces(nodes, speed, speedEfficiency, self.jitterTolerance)\n",
    "            speed = values['speed']\n",
    "            speedEfficiency = values['speedEfficiency']\n",
    "            applyforces_timer.stop()\n",
    "\n",
    "            # Add current positions to history\n",
    "            if keep_history:\n",
    "                positions = [(n.x, n.y) for n in nodes]\n",
    "                history.append(positions)\n",
    "\n",
    "        if self.verbose:\n",
    "            if self.barnesHutOptimize:\n",
    "                barneshut_timer.display()\n",
    "            repulsion_timer.display()\n",
    "            gravity_timer.display()\n",
    "            attraction_timer.display()\n",
    "            applyforces_timer.display()\n",
    "        # ================================================================\n",
    "        if not keep_history:\n",
    "            return [(n.x, n.y) for n in nodes]\n",
    "        else:\n",
    "            return positions, history\n",
    "\n",
    "    # A layout for NetworkX.\n",
    "    #\n",
    "    # This function returns a NetworkX layout, which is really just a\n",
    "    # dictionary of node positions (2D X-Y tuples) indexed by the node name.\n",
    "    def forceatlas2_networkx_layout(self, G, pos=None, sizes=None, iterations=100, keep_history=True):\n",
    "        import networkx\n",
    "        assert isinstance(G, networkx.classes.graph.Graph), \"Not a networkx graph\"\n",
    "        assert isinstance(pos, dict) or (pos is None), \"pos must be specified as a dictionary, as in networkx\"\n",
    "        assert isinstance(sizes, dict), \"adjustSizes=True requires a sizes dict to be passed\"\n",
    "        M = networkx.to_scipy_sparse_matrix(G, dtype='f', format='lil')\n",
    "        \n",
    "        if sizes is not None:\n",
    "            sizelist =  numpy.asarray([sizes[i] for i in G.nodes()])\n",
    "        else:\n",
    "            sizelist = None\n",
    "        \n",
    "        if pos is None:\n",
    "            l = self.forceatlas2(M, pos=None, iterations=iterations, sizes=sizelist, keep_history=keep_history)\n",
    "        else:\n",
    "            poslist = numpy.asarray([pos[i] for i in G.nodes()])\n",
    "            l = self.forceatlas2(M, pos=poslist, iterations=iterations, sizes=sizelist, keep_history=keep_history)\n",
    "        if not keep_history:\n",
    "            return dict(zip(G.nodes(), l))\n",
    "        else:\n",
    "            return [dict(zip(G.nodes(), i)) for i in l[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forceatlas2 = ForceAtlas2(\n",
    "                          # Behavior alternatives\n",
    "                          outboundAttractionDistribution=True,  # Dissuade hubs\n",
    "                          linLogMode=False,  # NOT IMPLEMENTED\n",
    "                          edgeWeightInfluence=1.0,\n",
    "\n",
    "                          # Performance\n",
    "                          jitterTolerance=1.0,  # Tolerance\n",
    "                          barnesHutOptimize=True,\n",
    "                          barnesHutTheta=1.2,\n",
    "                          multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                          # Tuning\n",
    "                          scalingRatio=500.0,\n",
    "                          gravity=1.0,\n",
    "\n",
    "                          # Log\n",
    "                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "new_graph = nx.readwrite.graphml.read_graphml('test.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bezier\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def curved_edges(G, pos, dist_ratio=0.2, bezier_precision=20, polarity='random'):\n",
    "    # Get nodes into np array\n",
    "    edges = np.array(G.edges())\n",
    "    l = edges.shape[0]\n",
    "\n",
    "    if polarity == 'random':\n",
    "        # Random polarity of curve\n",
    "        rnd = np.where(np.random.randint(2, size=l)==0, -1, 1)\n",
    "    else:\n",
    "        # Create a fixed (hashed) polarity column in the case we use fixed polarity\n",
    "        # This is useful, e.g., for animations\n",
    "        rnd = np.where(np.mod(np.vectorize(hash)(edges[:,0])+np.vectorize(hash)(edges[:,1]),2)==0,-1,1)\n",
    "    \n",
    "    # Coordinates (x,y) of both nodes for each edge\n",
    "    # e.g., https://stackoverflow.com/questions/16992713/translate-every-element-in-numpy-array-according-to-key\n",
    "    # Note the np.vectorize method doesn't work for all node position dictionaries for some reason\n",
    "    u, inv = np.unique(edges, return_inverse = True)\n",
    "    coords = np.array([pos[x] for x in u])[inv].reshape([edges.shape[0], 2, edges.shape[1]])\n",
    "    coords_node1 = coords[:,0,:]\n",
    "    coords_node2 = coords[:,1,:]\n",
    "    \n",
    "    # Swap node1/node2 allocations to make sure the directionality works correctly\n",
    "    should_swap = coords_node1[:,0] > coords_node2[:,0]\n",
    "    coords_node1[should_swap], coords_node2[should_swap] = coords_node2[should_swap], coords_node1[should_swap]\n",
    "    \n",
    "    # Distance for control points\n",
    "    dist = dist_ratio * np.sqrt(np.sum((coords_node1-coords_node2)**2, axis=1))\n",
    "\n",
    "    # Gradients of line connecting node & perpendicular\n",
    "    m1 = (coords_node2[:,1]-coords_node1[:,1])/(coords_node2[:,0]-coords_node1[:,0])\n",
    "    m2 = -1/m1\n",
    "\n",
    "    # Temporary points along the line which connects two nodes\n",
    "    # e.g., https://math.stackexchange.com/questions/656500/given-a-point-slope-and-a-distance-along-that-slope-easily-find-a-second-p\n",
    "    t1 = dist/np.sqrt(1+m1**2)\n",
    "    v1 = np.array([np.ones(l),m1])\n",
    "    coords_node1_displace = coords_node1 + (v1*t1).T\n",
    "    coords_node2_displace = coords_node2 - (v1*t1).T\n",
    "\n",
    "    # Control points, same distance but along perpendicular line\n",
    "    # rnd gives the 'polarity' to determine which side of the line the curve should arc\n",
    "    t2 = dist/np.sqrt(1+m2**2)\n",
    "    v2 = np.array([np.ones(len(edges)),m2])\n",
    "    coords_node1_ctrl = coords_node1_displace + (rnd*v2*t2).T\n",
    "    coords_node2_ctrl = coords_node2_displace + (rnd*v2*t2).T\n",
    "\n",
    "    # Combine all these four (x,y) columns into a 'node matrix'\n",
    "    node_matrix = np.array([coords_node1, coords_node1_ctrl, coords_node2_ctrl, coords_node2])\n",
    "\n",
    "    # Create the Bezier curves and store them in a list\n",
    "    curveplots = []\n",
    "    for i in range(l):\n",
    "        nodes = node_matrix[:,i,:].T\n",
    "        curveplots.append(bezier.Curve(nodes, degree=2).evaluate_multi(np.linspace(0,1,bezier_precision)).T)\n",
    "      \n",
    "    # Return an array of these curves\n",
    "    curves = np.array(curveplots)\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def animate_fa2(G, f, num_iterations=100, output_dir='/tmp', edge_type='straight'):\n",
    "\n",
    "    # Run FA2 and store the historical positions\n",
    "    historical_positions = f.forceatlas2_networkx_layout(G,\n",
    "                                                         pos=None,\n",
    "                                                         sizes=nx.get_node_attributes(G,'degree'),\n",
    "                                                         iterations=num_iterations,\n",
    "                                                         keep_history=True)\n",
    "\n",
    "    # Find the plot limits\n",
    "    # This allows a fixed x,y axis so the animation doesn't continuously rescale\n",
    "    all_positions = []\n",
    "    for positions in historical_positions:\n",
    "        for node_id in positions:\n",
    "            all_positions.append(positions[node_id])\n",
    "    all_positions = np.array(all_positions)\n",
    "    xmin, ymin = all_positions.min(axis=0)\n",
    "    xmax, ymax = all_positions.max(axis=0)\n",
    "    \n",
    "    # Plot\n",
    "    num_zeros = len(str(num_iterations))\n",
    "    i = 0\n",
    "    plt.ioff() # Incase you're running in a notebook, this will stop it displaying n plots\n",
    "    options = {\n",
    "    'node_color': [node[1]['partition'] for node in G.nodes(data=True)], \n",
    "    'node_size': [node[1]['degree'] for node in G.nodes(data=True)],\n",
    "    #'edge_color': [edge[2]['color'] for edge in nxG.edges(data=True)],\n",
    "    'linewidths': 0.0,\n",
    "    'width': 0.0\n",
    "}\n",
    "    \n",
    "    for positions in historical_positions:\n",
    "        plt.figure(i, figsize=(10,10))\n",
    "        plt.gca().set_facecolor('k')\n",
    "        \n",
    "        # Draw straight line edges\n",
    "        if edge_type == 'straight':\n",
    "            nx.draw_networkx_edges(G, positions, width=1, **options , alpha=0.1)\n",
    "        \n",
    "        # Draw curved lines ala Gephi - see https://github.com/beyondbeneath/bezier-curved-edges-networkx\n",
    "        else:\n",
    "            curves = curved_edges(G, positions, polarity='fixed')\n",
    "            lc = LineCollection(curves, color='w', alpha=0.1)\n",
    "            plt.gca().add_collection(lc)\n",
    "        \n",
    "        # Draw nodes and finish up\n",
    "        nx.draw_networkx_nodes(G, positions, **options)\n",
    "        plt.tick_params(axis='both',which='both',bottom=False,left=False,labelbottom=False,labelleft=False)\n",
    "        plt.xlim(xmin, xmax)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plot_filename = 'anim_frame_{}.png'.format(str(i).zfill(num_zeros))\n",
    "        plt.savefig(os.path.join(output_dir, plot_filename), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Increment plot counter\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:55,  1.77it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:01<01:01,  1.58it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:02<01:21,  1.19it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:04<01:40,  1.05s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:06<02:05,  1.32s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:08<02:22,  1.51s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:09<02:23,  1.55s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:11<02:20,  1.53s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:12<02:13,  1.47s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:14<02:13,  1.48s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:15<02:12,  1.49s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:16<02:08,  1.46s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:18<02:09,  1.49s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:20<02:08,  1.49s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:21<02:05,  1.48s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:23<02:05,  1.50s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:24<02:03,  1.49s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:26<02:02,  1.49s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:27<02:00,  1.49s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:29<02:00,  1.50s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:30<02:02,  1.55s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:32<02:09,  1.66s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:34<02:13,  1.73s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:36<02:10,  1.72s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:37<02:08,  1.71s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:39<02:07,  1.73s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:41<02:03,  1.69s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:42<02:02,  1.70s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:44<02:02,  1.72s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:46<02:00,  1.72s/it]\u001b[A\n",
      " 31%|███       | 31/100 [00:48<01:57,  1.71s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:49<01:54,  1.69s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:51<01:52,  1.68s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:53<01:51,  1.69s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:54<01:50,  1.70s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:57<01:58,  1.86s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:58<01:56,  1.85s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:00<01:54,  1.84s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:02<01:58,  1.95s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:04<01:57,  1.96s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:07<01:59,  2.02s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:09<02:01,  2.09s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:11<01:55,  2.03s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:13<01:55,  2.06s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:15<01:56,  2.11s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:17<01:52,  2.09s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:19<01:50,  2.09s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:21<01:44,  2.00s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:23<01:40,  1.96s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:25<01:34,  1.89s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:27<01:33,  1.92s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:28<01:31,  1.91s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:30<01:28,  1.88s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:33<01:31,  1.99s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:35<01:29,  2.00s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:36<01:24,  1.92s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:38<01:19,  1.86s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [01:40<01:16,  1.83s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [01:41<01:13,  1.78s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [01:43<01:11,  1.78s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [01:45<01:09,  1.77s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [01:47<01:07,  1.79s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [01:49<01:05,  1.77s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [01:50<01:03,  1.75s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [01:52<01:01,  1.75s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [01:54<00:59,  1.74s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [01:56<00:58,  1.77s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [01:58<00:58,  1.84s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [01:59<00:57,  1.84s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:01<00:55,  1.84s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:03<00:54,  1.89s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:05<00:54,  1.93s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:07<00:52,  1.94s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:09<00:50,  1.93s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:11<00:49,  1.97s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:13<00:47,  1.99s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:15<00:44,  1.92s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:17<00:43,  1.98s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:19<00:41,  1.95s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:21<00:37,  1.90s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:23<00:35,  1.89s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:24<00:33,  1.86s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:26<00:32,  1.91s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:28<00:29,  1.84s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [02:30<00:27,  1.80s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [02:32<00:25,  1.83s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [02:34<00:24,  1.91s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [02:36<00:22,  1.88s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [02:37<00:20,  1.82s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [02:39<00:17,  1.76s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [02:41<00:15,  1.72s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [02:42<00:13,  1.69s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [02:44<00:11,  1.66s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [02:46<00:10,  1.72s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [02:47<00:08,  1.74s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [02:49<00:06,  1.72s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [02:51<00:05,  1.78s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [02:53<00:03,  1.83s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [02:55<00:01,  1.87s/it]\u001b[A\n",
      "100%|██████████| 100/100 [02:57<00:00,  1.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BarnesHut Approximation  took  14.62  seconds\n",
      "Repulsion forces  took  156.14  seconds\n",
      "Gravitational forces  took  0.83  seconds\n",
      "Attraction forces  took  2.60  seconds\n",
      "AdjustSpeedAndApplyForces step  took  2.48  seconds\n"
     ]
    }
   ],
   "source": [
    "f = ForceAtlas2(\n",
    "                          # Behavior alternatives\n",
    "                          outboundAttractionDistribution=True,  # Dissuade hubs\n",
    "                          linLogMode=False,  # NOT IMPLEMENTED\n",
    "                          edgeWeightInfluence=1.0,\n",
    "\n",
    "                          # Performance\n",
    "                          jitterTolerance=1.0,  # Tolerance\n",
    "                          barnesHutOptimize=True,\n",
    "                          barnesHutTheta=1.2,\n",
    "                          multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                          # Tuning\n",
    "                          scalingRatio=500.0,\n",
    "                          gravity=1.0,\n",
    "\n",
    "                          # Log\n",
    "                          verbose=True)\n",
    "\n",
    "animate_fa2(new_graph, f, num_iterations=100, output_dir='fa2images/', edge_type='curved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fa2images/anim_frame_000.png', 'fa2images/anim_frame_001.png', 'fa2images/anim_frame_002.png', 'fa2images/anim_frame_003.png', 'fa2images/anim_frame_004.png', 'fa2images/anim_frame_005.png', 'fa2images/anim_frame_006.png', 'fa2images/anim_frame_007.png', 'fa2images/anim_frame_008.png', 'fa2images/anim_frame_009.png', 'fa2images/anim_frame_010.png', 'fa2images/anim_frame_011.png', 'fa2images/anim_frame_012.png', 'fa2images/anim_frame_013.png', 'fa2images/anim_frame_014.png', 'fa2images/anim_frame_015.png', 'fa2images/anim_frame_016.png', 'fa2images/anim_frame_017.png', 'fa2images/anim_frame_018.png', 'fa2images/anim_frame_019.png', 'fa2images/anim_frame_020.png', 'fa2images/anim_frame_021.png', 'fa2images/anim_frame_022.png', 'fa2images/anim_frame_023.png', 'fa2images/anim_frame_024.png', 'fa2images/anim_frame_025.png', 'fa2images/anim_frame_026.png', 'fa2images/anim_frame_027.png', 'fa2images/anim_frame_028.png', 'fa2images/anim_frame_029.png', 'fa2images/anim_frame_030.png', 'fa2images/anim_frame_031.png', 'fa2images/anim_frame_032.png', 'fa2images/anim_frame_033.png', 'fa2images/anim_frame_034.png', 'fa2images/anim_frame_035.png', 'fa2images/anim_frame_036.png', 'fa2images/anim_frame_037.png', 'fa2images/anim_frame_038.png', 'fa2images/anim_frame_039.png', 'fa2images/anim_frame_040.png', 'fa2images/anim_frame_041.png', 'fa2images/anim_frame_042.png', 'fa2images/anim_frame_043.png', 'fa2images/anim_frame_044.png', 'fa2images/anim_frame_045.png', 'fa2images/anim_frame_046.png', 'fa2images/anim_frame_047.png', 'fa2images/anim_frame_048.png', 'fa2images/anim_frame_049.png', 'fa2images/anim_frame_050.png', 'fa2images/anim_frame_051.png', 'fa2images/anim_frame_052.png', 'fa2images/anim_frame_053.png', 'fa2images/anim_frame_054.png', 'fa2images/anim_frame_055.png', 'fa2images/anim_frame_056.png', 'fa2images/anim_frame_057.png', 'fa2images/anim_frame_058.png', 'fa2images/anim_frame_059.png', 'fa2images/anim_frame_060.png', 'fa2images/anim_frame_061.png', 'fa2images/anim_frame_062.png', 'fa2images/anim_frame_063.png', 'fa2images/anim_frame_064.png', 'fa2images/anim_frame_065.png', 'fa2images/anim_frame_066.png', 'fa2images/anim_frame_067.png', 'fa2images/anim_frame_068.png', 'fa2images/anim_frame_069.png', 'fa2images/anim_frame_070.png', 'fa2images/anim_frame_071.png', 'fa2images/anim_frame_072.png', 'fa2images/anim_frame_073.png', 'fa2images/anim_frame_074.png', 'fa2images/anim_frame_075.png', 'fa2images/anim_frame_076.png', 'fa2images/anim_frame_077.png', 'fa2images/anim_frame_078.png', 'fa2images/anim_frame_079.png', 'fa2images/anim_frame_080.png', 'fa2images/anim_frame_081.png', 'fa2images/anim_frame_082.png', 'fa2images/anim_frame_083.png', 'fa2images/anim_frame_084.png', 'fa2images/anim_frame_085.png', 'fa2images/anim_frame_086.png', 'fa2images/anim_frame_087.png', 'fa2images/anim_frame_088.png', 'fa2images/anim_frame_089.png', 'fa2images/anim_frame_090.png', 'fa2images/anim_frame_091.png', 'fa2images/anim_frame_092.png', 'fa2images/anim_frame_093.png', 'fa2images/anim_frame_094.png', 'fa2images/anim_frame_095.png', 'fa2images/anim_frame_096.png', 'fa2images/anim_frame_097.png', 'fa2images/anim_frame_098.png', 'fa2images/anim_frame_099.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [05:58<02:02,  1.32s/it]\n",
      "t:   0%|          | 0/100 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 4/100 [00:00<00:02, 37.35it/s, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file fa2images/fa2image.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   7%|▋         | 7/100 [00:00<00:02, 33.83it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 10/100 [00:00<00:02, 32.04it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 13/100 [00:00<00:03, 27.87it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 16/100 [00:00<00:03, 25.63it/s, now=None]\u001b[A\n",
      "t:  19%|█▉        | 19/100 [00:00<00:03, 23.74it/s, now=None]\u001b[A\n",
      "t:  22%|██▏       | 22/100 [00:00<00:03, 23.99it/s, now=None]\u001b[A\n",
      "t:  25%|██▌       | 25/100 [00:00<00:03, 24.49it/s, now=None]\u001b[A\n",
      "t:  28%|██▊       | 28/100 [00:01<00:03, 22.92it/s, now=None]\u001b[A\n",
      "t:  31%|███       | 31/100 [00:01<00:02, 23.15it/s, now=None]\u001b[A\n",
      "t:  34%|███▍      | 34/100 [00:01<00:02, 22.48it/s, now=None]\u001b[A\n",
      "t:  37%|███▋      | 37/100 [00:01<00:02, 22.58it/s, now=None]\u001b[A\n",
      "t:  40%|████      | 40/100 [00:01<00:02, 21.57it/s, now=None]\u001b[A\n",
      "t:  43%|████▎     | 43/100 [00:01<00:02, 21.57it/s, now=None]\u001b[A\n",
      "t:  46%|████▌     | 46/100 [00:01<00:02, 20.95it/s, now=None]\u001b[A\n",
      "t:  49%|████▉     | 49/100 [00:02<00:02, 21.04it/s, now=None]\u001b[A\n",
      "t:  52%|█████▏    | 52/100 [00:02<00:02, 20.41it/s, now=None]\u001b[A\n",
      "t:  55%|█████▌    | 55/100 [00:02<00:02, 20.75it/s, now=None]\u001b[A\n",
      "t:  58%|█████▊    | 58/100 [00:02<00:02, 20.54it/s, now=None]\u001b[A\n",
      "t:  61%|██████    | 61/100 [00:02<00:01, 20.38it/s, now=None]\u001b[A\n",
      "t:  64%|██████▍   | 64/100 [00:02<00:01, 19.00it/s, now=None]\u001b[A\n",
      "t:  66%|██████▌   | 66/100 [00:03<00:01, 18.83it/s, now=None]\u001b[A\n",
      "t:  68%|██████▊   | 68/100 [00:03<00:01, 18.89it/s, now=None]\u001b[A\n",
      "t:  70%|███████   | 70/100 [00:03<00:01, 18.12it/s, now=None]\u001b[A\n",
      "t:  72%|███████▏  | 72/100 [00:03<00:01, 18.00it/s, now=None]\u001b[A\n",
      "t:  74%|███████▍  | 74/100 [00:03<00:01, 17.76it/s, now=None]\u001b[A\n",
      "t:  76%|███████▌  | 76/100 [00:03<00:01, 17.58it/s, now=None]\u001b[A\n",
      "t:  78%|███████▊  | 78/100 [00:03<00:01, 17.11it/s, now=None]\u001b[A\n",
      "t:  80%|████████  | 80/100 [00:03<00:01, 16.57it/s, now=None]\u001b[A\n",
      "t:  82%|████████▏ | 82/100 [00:03<00:01, 16.58it/s, now=None]\u001b[A\n",
      "t:  84%|████████▍ | 84/100 [00:04<00:00, 16.36it/s, now=None]\u001b[A\n",
      "t:  86%|████████▌ | 86/100 [00:04<00:00, 15.38it/s, now=None]\u001b[A\n",
      "t:  88%|████████▊ | 88/100 [00:04<00:00, 14.24it/s, now=None]\u001b[A\n",
      "t:  90%|█████████ | 90/100 [00:04<00:00, 13.19it/s, now=None]\u001b[A\n",
      "t:  92%|█████████▏| 92/100 [00:04<00:00, 12.80it/s, now=None]\u001b[A\n",
      "t:  94%|█████████▍| 94/100 [00:04<00:00, 13.19it/s, now=None]\u001b[A\n",
      "t:  96%|█████████▌| 96/100 [00:05<00:00, 13.37it/s, now=None]\u001b[A\n",
      "t:  98%|█████████▊| 98/100 [00:05<00:00, 13.04it/s, now=None]\u001b[A\n",
      "t: 100%|██████████| 100/100 [00:05<00:00, 13.08it/s, now=None]\u001b[A\n",
      "                                                              \u001b[A"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import moviepy.editor as mpy\n",
    "gif_name = 'fa2image'\n",
    "fps = 12\n",
    "file_list = glob.glob('fa2images/*.png') # Get all the pngs in the current directory\n",
    "print(file_list)\n",
    "list.sort(file_list, key=lambda x: int(x.split('_')[2].split('.png')[0])) # Sort the images by #, this may need to be tweaked for your use case\n",
    "clip = mpy.ImageSequenceClip(file_list, fps=fps)\n",
    "clip.write_gif('fa2images/{}.gif'.format(gif_name), fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/b8005c49fd3975a9660dfd648292bb043a5d811fe17339e8f7b79f3ec796/moviepy-1.0.1.tar.gz (373kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in ./anaconda3/envs/graphs/lib/python3.6/site-packages (from moviepy) (4.4.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in ./anaconda3/envs/graphs/lib/python3.6/site-packages (from moviepy) (4.41.1)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/graphs/lib/python3.6/site-packages (from moviepy) (1.15.4)\n",
      "Collecting requests<3.0,>=2.8.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proglog<=1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n",
      "Collecting imageio<3.0,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/de/f7f985018f462ceeffada7f6e609919fbcc934acd9301929cba14bc2c24a/imageio-2.6.1-py3-none-any.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/12/01126a2fb737b23461d7dadad3b8abd51ad6210f979ff05c6fa9812dfbbe/imageio_ffmpeg-0.3.0-py3-none-manylinux2010_x86_64.whl (22.2MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2MB 772kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 13.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 13.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/graphs/lib/python3.6/site-packages (from requests<3.0,>=2.8.1->moviepy) (2019.11.28)\n",
      "Collecting pillow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/5e/23dcc0ce3cc2abe92efd3cd61d764bee6ccdf1b667a1fb566f45dc249953/Pillow-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: moviepy, proglog\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.1-cp36-none-any.whl size=110786 sha256=a2f2abebe08e93fdcfe92934e634e7838ed47065780fde2b1444e82eba0f842c\n",
      "  Stored in directory: /home/v-saflor/.cache/pip/wheels/a3/3c/07/45afe2bd5dbd3f935f445545d645f0f8c05d48340136367d45\n",
      "  Building wheel for proglog (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for proglog: filename=proglog-0.1.9-cp36-none-any.whl size=6148 sha256=e9aa4727fff1e6df442975ce5c70da7cf3ecaf6bbe1cd666071ee23c5d7f3591\n",
      "  Stored in directory: /home/v-saflor/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n",
      "Successfully built moviepy proglog\n",
      "Installing collected packages: chardet, idna, urllib3, requests, proglog, pillow, imageio, imageio-ffmpeg, moviepy\n",
      "Successfully installed chardet-3.0.4 idna-2.8 imageio-2.6.1 imageio-ffmpeg-0.3.0 moviepy-1.0.1 pillow-7.0.0 proglog-0.1.9 requests-2.22.0 urllib3-1.25.7\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nx.draw(new_graph, positions, **options, with_labels=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
